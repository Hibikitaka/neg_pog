\expandafter\ifx\csname ifdraft\endcsname\relax
 \documentclass{jsarticle}
 \begin{document}
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\def\Path{./5_Metaheuristic}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{メタ戦略\cite{Yag-Iba:2001}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
本章では，まず，組合せ最適化問題に対するメタ戦略について説明する．
次に，メタ戦略の基本戦略である局所探索法について述べる．
まず，代表的なメタ戦略の例として反復局所探索法について述べ，我々が改良する元のアルゴリズムであるMBOについて説明する

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{メタ戦略}
組合せ最適化問題は，その多くがNP-困難である．しかし，現実には，解きたい問題が難しいからといって，解くことをあきらめるわけにはいかない．
幸い，最適性の保証は無くとも，ある程度精度の高い解が求まれば，十分満足のいく場合が多い．そこで，現実的な時間で良質の解を求めるために
近似解法(approximate algorithm)や発見的手法(heuristics)が用いられる．

近似解法の基本戦略として，欲張り法(greedy method)や局所探索法(local search)が挙げられる．
欲張り法は，目的関数への貢献度を示す局所的な評価値に基づいて，実行可能解を直接構成する方法で，構築法(constructive algorithm)の一種である．
これに対し，局所探索法は，与えられた解を簡単な操作によって改善する手続きを反復する方法で，改善法(improvement algorithm; 修繕法(repair method))の一種である．
これら基本戦略の内，局所探索法については\ref{sec:ls}節で詳しく説明する．
メタ戦略(metaheuristics; メタ解法，メタヒューリスティクスとも呼ぶ)は，これらの基本戦略よりも多少時間はかかっても，より良質の解を求めるような解法の
一般的枠組を与えるものである．代表的なメタ戦略として，遺伝アルゴリズム(genetic algorithm)，アニーリング法(simulated annealing)，タブー探索法(tabu search)などがある．

局所探索法やメタ戦略は，解を生成してはその目的関数値や実行可能性を評価するという操作を反復するものである．
すなわち，生成された解のどのような情報を探索履歴として記憶するか，過去の探索の履歴をどのように利用して新たな解を生成するか，に対する様々なアイデアの集合がメタ戦略であるといえる．
クラスNPに含まれる問題では，解$s$の目的関数値や実行可能性を判定する多項式時間アルゴリズム$A$の存在が仮定されているので，判定の評価は多項式時間で実行できる．このような意味において，クラスNPとメタ戦略は相性が良い．
ただし，メタ戦略は非決定性計算による$s$の列挙を陽には行わず，決定計算である局所探索によって，解の集合の一部のみを生成する点が本質的に異なる．
メタ戦略が有効な理由は，局所探索によって生成される解の集合が比較的良い目的関数値の実行可能解を多く含んでいるという理由による．
この探索領域に最適解が含まれていれば，対象問題例を厳密に解いたことになり，そうでなくても，最適に近い解が含まれていれば，近似的に解いていることになる．

メタ戦略の多くは，「良い解どうしは似通った構造を持っている」，POP(proximate optimality principle)と呼ばれる概念に基づいて設計されている．
POPが成立していれば，よい解と似通った解の中により良い解が含まれている可能性が高いと考えられる．
局所探索法が持つ優良な解を見つける能力である改善力とPOPに基づいて，良い解の周辺を集中的に探索しようとする考え方を探索の集中化(intensification)と呼び，メタ戦略の基本原理の一つである．
一方，似通った構造の解ばかりを探索していると，同じ解を何度も探索してしまい，無駄な探索になってしまう恐れもある．よってときおりは，これまでに生成されてきた解とは構造の異なる解を生成することも必要である．
この考え方は探索の多様化(diversification)とよばれ，メタ戦略のもう一つの基本原理である．メタ戦略による探索は，これらの互いに相反する原理をいかにバランスよく組み込むことが重要である．
図\ref{fig:enu}，\ref{fig:meta}に以上の議論を模式的に表し，列挙法とメタ戦略を対比したものを示す．

\begin{figure}[h]
	\begin{minipage}{0.5\hsize}
	\centering
	\includegraphics[scale=0.3]{\Path/Image/rekkyo_search.png}
	\caption{列挙法の探索}
	\label{fig:enu}
	\end{minipage}
	\begin{minipage}{0.5\hsize}
	\centering
	\includegraphics[scale=0.3]{\Path/Image/meta_search.png}
	\caption{メタ戦略の探索}
	\label{fig:meta}
	\end{minipage}
\end{figure}


\section{局所探索法}\label{sec:ls}
本節では，メタ戦略の基本戦略である局所探索法について述べる．

局所探索法は，手元にある解(例えば欲張り法で構成されたもの)の改良を試みる一般的な手順である．さらにメタ戦略は局所探索法の一般化と捉えることができる．
最適化問題において，実行可能解$x \in F$に対し，$x$に少しの変形を加えることによって得られる解集合$N(x) \subset F$を$x$の近傍(neighborhood)と呼ぶ．
局所探索法は近傍$N(x)$内に改善解が存在しなくなるまで反復する方法である．
近傍$N(x)$内の改善解は，一般に複数個存在するので，近傍をどのような順序で調べ，どの解を次の解として採用するかについては，様々な戦略が可能である．このルールを移動戦略(move strategy)という．代表的なものとして，
\begin{description}
  \item[a)]近傍$N(x)$内をランダムな順序で調べて最初に見つかった改善解に移動する即時移動戦略(first admissible move strategy) 
\end{description}
\begin{description}
  \item[b)]$N(x)$内の解をすべて調べて最良解に移動する最良移動戦略(best admissible strategy)
\end{description}
の2つがある．

近傍$N(x)$は，数学的には写像$N：F\to 2^{F}$であれば，何でもよいが，性能の高い局所探索法を得るには，$N(x)$内に改善解が存在する傾向が高くなるように定めることが重要である．これには，問題の性質をいかに取り込むかがポイントである．
巡回セールスマン問題や1機械スケジューリング問題のように，解が要素集合$V={1,...,n}$の順列$\sigma $で表される場合は，
\begin{flushleft}
$N_{ins}(\sigma )=${$\Sigma $の1つの要素を他の位置に挿入することにより得られる解}
\end{flushleft}

\begin{flushleft}
$N_{swap}(\sigma )=${$\Sigma $の2つの要素の位置を交換することにより得られる解}
\end{flushleft}
などがよく利用される．$N_{ins}$を挿入近傍(insertion neighborhood)，$N_{swap}$を交換近傍(swap neighborhood)と呼ぶ．
%\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{反復局所探索法} \label{sec:ils}
本節では，代表的なメタ戦略の例として，本研究で対象とする反復局所探索法について記述する．
まず，反復局所探索法の研究背景について述べ，次に反復局所探索法の手続きを示す．

\subsection{反復局所探索法の研究背景} \label{ssec:ils-hist}
反復局所探索法(Iterated Local Search, ILS)は，過去の探索で得られた良い解にランダムな変形を加えたものを初期解として，局所探索法を反復する方法である．
初期解生成に利用する解として，常に暫定解を利用するという，最も単純な方法は，Johnsonにより提案された．
初期解生成に利用する解の選択方法に，アニーリング法に類似のアイデアを用いてランダム性を導入した方法もある．
反復局所探索法のこのような変形は連鎖局所探索法(Chained Local Optimization, CLO; Large-step Markov Chainとも呼ぶ)と呼ばれる．
また，初期解生成について，使用する近傍のサイズを適応的に変化させる方法も提案されている．近傍サイズを，初めは小さく設定するが，初期解の生成に用いる局所最適解と局所探索法によって
新たに得られた解を比べて改善が見られない場合には徐々に大きくしていき，改善解が得られた場合は初めの近傍に戻す(ただし，局所探索法の近傍は常に同じものを用いる)．
このような方法は可変近傍探索法(Variable Neighborhood Search, VNS)と呼ばれる．

\subsection{反復局所探索法の手続き} \label{ssec:ils-proc}
反復局所探索法の手続きを図\ref{fig:ils-basic}に示す．アルゴリズム中，$x$は，次の局所探索の初期解を生成するために利用される解を表す．
解に加えるランダムな変形はKickと呼ばれる．反復局所探索法において，Kickは重要な設計要素である．Kickには図\ref {fig:ils-basic}のように探索中に得た最適解を変形する手法や，その時得た局所最適解$x'$を変形する手法などがある．
終了条件を満たせば，これまでに得た最良の解を出力して探索を終了する(ステップ5)．

\input{\Path/Code/ILS_Procedure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{反復貪欲法} \label{sec:IG}
本節では，FSPにおいて極めての効率的な解法であるRuizとStutzleによる反復貪欲法~\cite{ruiz2007simple}について記述する．まず，反復貪欲法の研究背景について述べ，次に反復貪欲法の手続きを示す．

\section{反復貪欲法の研究背景} \label{ssec:IG}
RuizとStutzleによる反復貪欲法(Iterated Greedy,IG)~\cite{ruiz2007simple}は，FSPにおいて効率的なNEHヒューリスティック基づいたアルゴリズムである．近年のメタヒューリスティックでは，許容可能な計算時間で優れた結果を残しているが提案されている手法の中には過度に複雑になっている．場合によっては発表されているアルゴリズムが非常に複雑でコーディング行っても同じ効果を得られない可能性がある．IGはコード化が簡単で非常に効果的であるアルゴリズムである．またIGはパラメータが２つしかなく調整が容易である．

\subsection{反復貪欲法の手続き} \label{ssec:IG-hist}
RuizとStutzleによる反復貪欲法~\cite{ruiz2007simple}の擬似コードを図\ref{IGcode}に示す．このアルゴリズムは初期解生成，破壊処理，構築処理，局所探索，SAの要素で構成されている．
初期解生成ではNEHアルゴリズムを用いる．破壊処理では与えられた解から一部を取り除き，構築処理にてNEHヒューリスティックと同様にジョブを挿入する．次にその解に対して局所探索を行う．局所探索の擬似コードは図\ref{LScode}に示す．
SAについては\ref{sec:SA}にて説明するが，IGにおいては解の多様性を持たせるために行っており以下の式を用いて適用される．

 \input{\Path/Code/IG}
  \input{\Path/Code/LS}
  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{焼きなまし法(Simulated Aniling, SA)} \label{sec:SA}
本節では，FSPにおいてOsmanとPottsによって適用された焼きなまし法~\cite{osman1989simulated}について記述する．まず，焼きなまし法の研究背景について述べ，次にや焼きなまし法の手続きを示す．

\subsection{焼きなまし法の背景} \label{ssec:SA}
機械が２台の場合，johnson法によって効率的なアルゴリズムで問題が解決される．しかし３台以上の機械の場合，NP困難であるため，最適解を得ることは難しく，発見的手法の欠点を補った改善型ヒューリスティックを用いることが有効であると考える．そこで当時，注目されていた焼きなまし法を用いる．焼きなまし法はある確率で評価値を増加させる解を受け入れるランダムな改善手法である．
\subsection{焼きなまし法の手続き} \label{ssec:SA2}
OsmanとPottsによって適用された焼きなまし法~\cite{osman1989simulated}は繰り返して近傍を生成し，ある確率で評価値を増加させる解を受け入れる改善手法である．
近傍生成にはシフト近傍を用いている．またSAの重要な設計要素である評価値を増加させる解を受け入れる確率は$R \leq e^{-\Delta,T}$で表される．
確率に用いられる初期温度は\ref{TK}とし最終温度は\ref{T1}とした．反復回数は\ref{K}とし，$K,T_1,T_k$が決定されると$\beta$は\ref{beta}式となる


\vspace*{-0.5cm}
\begin{eqnarray}
%\hspace*{-0.5cm}　C(\pi) =\text{max}(f_{i, j})  \nonumber \\	
%	 j\in J, i \in M%%maxを文字にする
	T_{k+1} = T_k/(1+\beta T_k)
	\label{TK}
\end{eqnarray}
\vspace*{-0.3cm}

\vspace*{-0.5cm}
\begin{eqnarray}
%\hspace*{-0.5cm}　C(\pi) =\text{max}(f_{i, j})  \nonumber \\	
%	 j\in J, i \in M%%maxを文字にする
	T_{l} = \sum_{i=1}^{n}\sum_{j=1}^{m}p_{i,j}/(5nm)
	\label{Tl}
\end{eqnarray}
\vspace*{-0.3cm}

\vspace*{-0.5cm}
\begin{eqnarray}
%\hspace*{-0.5cm}　C(\pi) =\text{max}(f_{i, j})  \nonumber \\	
%	 j\in J, i \in M%%maxを文字にする
	T_{k} = 1
	\label{T1}
\end{eqnarray}
\vspace*{-0.3cm}

% \vspace*{-0.5cm}
% \begin{eqnarray}
% %\hspace*{-0.5cm}　C(\pi) =\text{max}(f_{i, j})  \nonumber \\	
% %	 j\in J, i \in M%%maxを文字にする
% 	k = \rm{max}{3300 \rm{In} n + 7500 \rm{In} m -18250,2000}
% 	\label{K}
% \end{eqnarray}
% \vspace*{-0.3cm}

\vspace*{-0.5cm}
\begin{eqnarray}
%\hspace*{-0.5cm}　C(\pi) =\text{max}(f_{i, j})  \nonumber \\	
%	 j\in J, i \in M%%maxを文字にする
	\beta = (T_l-T_k)/(K-1)T_l T_k)
	\label{beta}
\end{eqnarray}
\vspace*{-0.3cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section{遺伝的アルゴリズム(Genetic Alorithm, GA)} \label{sec:SA}


% \subsection{遺伝的アルゴリズムの手続き} \label{ssec:SA}


\section{渡り鳥最適化アルゴリズム} \label{sec:MBO}
本節では，本研究で対象とするDuman, Ekrem,Uysalらによって提案された渡り鳥最適化アルゴリズム\cite{duman2012migrating}について記述する．
まず，現実の渡り鳥について述べ，次に渡り鳥最適アルゴリズムの手続きを示す．

\subsection{現実の渡り鳥} \label{ssec:MBO-hist}
渡り鳥の群れは長距離飛行を行う際，V字型編隊を組む図\ref{formation}．これには２つの仮説が提案されている．第一に飛行中のエネルギーが節約されることが挙げられる．第二に，鳥同士がお互いの衝突を避け，視界を防がないようにしていると考えられている．
V字型のフォーメーションでは，先頭を飛んでいるリーダーの鳥が最も多くのエネルギーを消費する．それ以外の鳥は，先頭の鳥からエネルギー節約の恩恵を受けている．一般的には，リーダーの鳥がしばらく飛び，疲弊すると列の最後尾につき，後続の鳥がリーダーになると考えられている．通常，鳥の群れは同じ家族で構成され，最も強い鳥がリーダーとなるか，複数の家族を組み合わせて強い鳥がリーダーになる．理論的には，鳥の数が多いほどエネルギーの節約が大きくなるが，実際に観測された群れの大きさは限られている．理由として群れのサイズが大きくなりすぎると，協調性を失い列を組むのが難しくなるためである．その結果，後方の鳥は編隊飛行のエネルギー節約の恩恵を受けることはできなくなる．

\begin{figure}
	\centering
	\includegraphics[width=15cm]{\Path /Image/bird.PNG}
	\caption{V字型編隊のイメージ}
	\label{formation}
\end{figure}


\subsection{渡り鳥アルゴリズム最適化の手続き} \label{ssec:MBO-proc}
Duman, Ekrem,Uysalらによって提案された渡り鳥最適化アルゴリズムの擬似コードをを図\ref{code:mbo}に示す．
Line 1では$n$個のランダムな初期解を生成し，評価値順に初期解を仮想的なV字型に並べる．
Line 5ではリーダー(解を仮想的なV字型に並べた時に先頭に来る解)に対して近傍を$k$個生成し，生成された近傍が良好な解であれば解の更新を行う．Line 7,8はリーダー以外の解の更新を行っている．この時更新を行う解からの近傍を$k-x$個，更新を行う解の一つ前の解から生成されたことのない近傍を$x$個生成する．これらの近傍解で良好な解を新しい解とする．Line12ではV字型配置の並び替えを行う．この並び替えでは，先頭にいた解を最後尾に置き後続の解を一つずつ前にする．このアルゴリズムは近傍回数が終了条件を満たすまで繰り返す．
% このアルゴリズムは初期解を擬似的にV字に配置することから始まる．
% その後，リーダーから末尾に向かって近傍を生成していく．その中で自分より前を飛ぶ鳥（解）から利益を得ている．つまりMBOでは各自の近傍解と前の解からの近傍により解を改善する．

 \input{\Path/Code/MBOProcedure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\expandafter\ifx\csname ifdraft\endcsname\relax
  \end{document}
\fi
